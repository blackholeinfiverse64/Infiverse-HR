# üöÄ BHIV HR Platform - START HERE

**Zero-Ambiguity Developer Handover for Ishan, Nikhil & Vinayak**

**Status**: Updated January 22, 2026 - Current Production System Documentation

## ‚ö° Quick Start (5 Minutes)

```bash
# 1. Clone and setup
git clone https://github.com/Shashank-0208/BHIV-HR-PLATFORM.git
cd BHIV-HR-Platform
cp .env.example .env

# 2. Start all services
docker-compose -f docker-compose.production.yml up -d --build


# 3. Test system
python test_complete_localhost.py
```

## üéØ Current Production System Status (Jan 2026)

**üîç Microservice Architecture Active**:
* ‚úÖ **API Gateway** (Port 8000) - 77 endpoints
* ‚úÖ **AI Agent** (Port 9000) - 6 endpoints
* ‚úÖ **LangGraph** (Port 9001) - 25 endpoints
* ‚úÖ **MongoDB Atlas** - Primary database (fully migrated from PostgreSQL)

| Component | Status | Your Action |
|-----------|--------|-------------|
| **RL Integration** | ‚úÖ COMPLETE | Fully integrated in LangGraph - see `/rl/` endpoints |
| **AI Brain Wiring** | ‚úÖ COMPLETE | Integrated with LangGraph workflows |
| **Database** | ‚úÖ MIGRATED | MongoDB Atlas (17+ collections) |
| **Authentication** | ‚úÖ WORKING | API keys, JWT, 2FA all functional |
| **Runtime-Core** | ‚ö†Ô∏è LEGACY | Reference implementation only (not in production) |

## üß† AI Integration Status (FOR ISHAN)

### Current Status
‚úÖ **AI Integration Complete**
- **LangGraph Service**: Fully integrated AI/ML workflows with 25 endpoints
- **Semantic Matching**: AI-powered candidate-job matching in Agent service
- **Reinforcement Learning**: RL integration in LangGraph for adaptive behavior
- **Multi-channel Communication**: AI-driven notifications (Email, WhatsApp, Telegram)

### Integration Architecture
The AI system is now fully integrated into the microservice architecture:

1. **LangGraph Service** (Port 9001)
   - Workflow automation with AI decision-making
   - RL integration for continuous learning
   - Multi-channel communication system

2. **Agent Service** (Port 9000)
   - Semantic candidate matching
   - Batch processing capabilities
   - ML-powered predictions

3. **Gateway Service** (Port 8000)
   - AI integration endpoints
   - Workflow orchestration
   - Real-time analytics

### Testing AI Integration
```bash
# Test LangGraph AI workflows
curl http://localhost:9001/workflows

# Test Agent semantic matching
curl -X POST http://localhost:9000/match \
  -H "Content-Type: application/json" \
  -d '{"job_id":"1"}'

# Test RL integration
curl http://localhost:9001/rl/
```

## üìã Critical Files (Current System)

| File | Purpose | Owner |
|------|---------|-------|
| `handover/START_HERE.md` | This file | All |
| `handover/FAQ.md` | Troubleshooting | All |
| `backend/README.md` | Main system documentation | All |
| `services/gateway/app/main.py` | API Gateway (Port 8000) | All |
| `services/agent/app.py` | AI Agent (Port 9000) | Ishan |
| `services/langgraph/app/main.py` | LangGraph (Port 9001) | Ishan |
| `run_services.py` | System orchestration | All |
| `docker-compose.production.yml` | Production deployment | All |
| `runtime-core/` | Legacy reference framework | Reference |
| `test_authentication_changes.py` | System validation | All |

## üÜò Emergency Contacts

- **System Issues**: Check `handover/FAQ.md`
- **AI Brain**: Contact Ishan
- **Database**: Check `docs/database/`
- **Deployment**: Check `docs/guides/DEPLOYMENT_GUIDE.md`

## ‚úÖ Validation Checklist (Current System)

- [ ] All services start: `python run_services.py`
- [ ] Tests pass: `python test_authentication_changes.py`
- [ ] MongoDB connection: `python test_mongodb_atlas.py`
- [ ] API endpoints functional: Check `http://localhost:8000/docs`
- [ ] AI/ML workflows: Check `http://localhost:9001/docs`
- [ ] Read FAQ: `handover/FAQ.md`

**Next Steps**: 
1. Read `handover/FAQ.md` for detailed operations guide
2. Review `backend/README.md` for complete system documentation
3. Check `docs/` folder for comprehensive technical documentation

**Legacy Note**: The `runtime-core/` folder contains the original framework implementation but is not used in production. The core functionality has been integrated directly into the main services for better maintainability.